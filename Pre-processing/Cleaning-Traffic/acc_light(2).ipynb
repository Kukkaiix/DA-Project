{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พบไฟล์ .csv ทั้งหมด 276 ไฟล์\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSVs: 100%|██████████| 276/276 [32:07<00:00,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ เสร็จสิ้น\n",
      "➡️ จำนวนแถวที่ผ่านเงื่อนไขทั้งหมด: 151,066,892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "INPUT_ROOT  = \"/Users/kukkaii/Documents/DA PRoject/Clean_RoadData/Tambon/Extracted_bz2\"\n",
    "OUTPUT_ROOT = \"/Users/kukkaii/Documents/DA PRoject/Clean_RoadData/Tambon/Filtered_engine1_light0\"\n",
    "\n",
    "\n",
    "CHUNK_SIZE  = 500_000\n",
    "\n",
    "\n",
    "STD_COLS = [\n",
    "    \"vehicle_id\",\"gps_valid\",\"lat\",\"lon\",\"timestamp\",\n",
    "    \"speed_kmh\",\"heading_deg\",\"for_hire_light\",\"engine_acc\"\n",
    "]\n",
    "REQUIRED = {\"lat\",\"lon\",\"timestamp\",\"speed_kmh\",\"engine_acc\",\"for_hire_light\"}\n",
    "KEEP_COLS = [\"lat\",\"lon\",\"timestamp\",\"speed_kmh\"]\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def sniff_has_header(path: str) -> bool:\n",
    "    \"\"\"ตรวจสอบเบื้องต้นว่าไฟล์มี header หรือไม่\"\"\"\n",
    "    try:\n",
    "        first_row = pd.read_csv(path, nrows=1, engine=\"python\", on_bad_lines=\"skip\")\n",
    "        cols = [c.strip().lower() for c in first_row.columns.tolist()]\n",
    "        return {\"timestamp\",\"lat\",\"lon\"}.issubset(set(cols))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def process_with_header(in_path: str, out_path: str) -> Tuple[int, Optional[str]]:\n",
    "    \"\"\"กรณีไฟล์มี header\"\"\"\n",
    "    written = 0\n",
    "    wrote_header = False\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "    try:\n",
    "        for chunk in pd.read_csv(\n",
    "            in_path,\n",
    "            chunksize=CHUNK_SIZE,\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\"\n",
    "        ):\n",
    "        \n",
    "            cols_lower = {c.lower(): c for c in chunk.columns}\n",
    "            if not REQUIRED.issubset(set(cols_lower.keys())):\n",
    "                missing = REQUIRED - set(cols_lower.keys())\n",
    "                return 0, f\"missing required columns: {missing}\"\n",
    "\n",
    "            # map column names\n",
    "            lat = cols_lower[\"lat\"]\n",
    "            lon = cols_lower[\"lon\"]\n",
    "            ts  = cols_lower[\"timestamp\"]\n",
    "            spd = cols_lower[\"speed_kmh\"]\n",
    "            eng = cols_lower[\"engine_acc\"]\n",
    "            light = cols_lower[\"for_hire_light\"]\n",
    "\n",
    "            # convert to numeric\n",
    "            chunk[eng]   = pd.to_numeric(chunk[eng], errors=\"coerce\")\n",
    "            chunk[light] = pd.to_numeric(chunk[light], errors=\"coerce\")\n",
    "\n",
    "            mask = (chunk[eng] == 1) & (chunk[light] == 0)\n",
    "            filtered = chunk.loc[mask, [lat, lon, ts, spd]].copy()\n",
    "            if filtered.empty:\n",
    "                continue\n",
    "\n",
    "            # add Date column\n",
    "            filtered[\"Date\"] = pd.to_datetime(filtered[ts], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "            filtered = filtered.dropna(subset=[\"Date\"])\n",
    "            filtered.columns = [\"lat\",\"lon\",\"timestamp\",\"speed_kmh\",\"Date\"]\n",
    "\n",
    "            ensure_dir(os.path.dirname(out_path))\n",
    "            filtered.to_csv(out_path, mode=\"a\", index=False, header=not wrote_header, encoding=\"utf-8-sig\")\n",
    "            wrote_header = True\n",
    "            written += len(filtered)\n",
    "\n",
    "        if written == 0 and os.path.exists(out_path):\n",
    "            os.remove(out_path)\n",
    "        return written, None\n",
    "    except Exception as e:\n",
    "        if os.path.exists(out_path) and os.path.getsize(out_path) == 0:\n",
    "            os.remove(out_path)\n",
    "        return 0, str(e)\n",
    "\n",
    "def process_no_header(in_path: str, out_path: str) -> Tuple[int, Optional[str]]:\n",
    "    \"\"\" no header\"\"\"\n",
    "    written = 0\n",
    "    wrote_header = False\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "    try:\n",
    "        for chunk in pd.read_csv(\n",
    "            in_path,\n",
    "            header=None,\n",
    "            names=STD_COLS,\n",
    "            chunksize=CHUNK_SIZE,\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\"\n",
    "        ):\n",
    "            chunk[\"engine_acc\"]    = pd.to_numeric(chunk[\"engine_acc\"], errors=\"coerce\")\n",
    "            chunk[\"for_hire_light\"]= pd.to_numeric(chunk[\"for_hire_light\"], errors=\"coerce\")\n",
    "\n",
    "            mask = (chunk[\"engine_acc\"] == 1) & (chunk[\"for_hire_light\"] == 0)\n",
    "            filtered = chunk.loc[mask, KEEP_COLS].copy()\n",
    "            if filtered.empty:\n",
    "                continue\n",
    "\n",
    "            filtered[\"Date\"] = pd.to_datetime(filtered[\"timestamp\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "            filtered = filtered.dropna(subset=[\"Date\"])\n",
    "\n",
    "            ensure_dir(os.path.dirname(out_path))\n",
    "            filtered.to_csv(out_path, mode=\"a\", index=False, header=not wrote_header, encoding=\"utf-8-sig\")\n",
    "            wrote_header = True\n",
    "            written += len(filtered)\n",
    "\n",
    "        if written == 0 and os.path.exists(out_path):\n",
    "            os.remove(out_path)\n",
    "        return written, None\n",
    "    except Exception as e:\n",
    "        if os.path.exists(out_path) and os.path.getsize(out_path) == 0:\n",
    "            os.remove(out_path)\n",
    "        return 0, str(e)\n",
    "\n",
    "def process_one_csv(in_path: str, out_path: str) -> Tuple[int, Optional[str]]:\n",
    "    \"\"\"เลือก process ตามว่ามี header หรือไม่\"\"\"\n",
    "    has_header = sniff_has_header(in_path)\n",
    "    if has_header:\n",
    "        return process_with_header(in_path, out_path)\n",
    "    else:\n",
    "        return process_no_header(in_path, out_path)\n",
    "\n",
    "def main():\n",
    "    csv_files = []\n",
    "    for root, _, files in os.walk(INPUT_ROOT):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(root, f))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ ไม่พบไฟล์ .csv ในโฟลเดอร์ต้นทาง\")\n",
    "        return\n",
    "\n",
    "    print(f\"พบไฟล์ .csv ทั้งหมด {len(csv_files)} ไฟล์\")\n",
    "    total_rows = 0\n",
    "    error_files = []\n",
    "\n",
    "    for in_path in tqdm(csv_files, desc=\"Processing CSVs\"):\n",
    "        rel_path = os.path.relpath(in_path, INPUT_ROOT)\n",
    "        out_path = os.path.join(OUTPUT_ROOT, rel_path)\n",
    "        ensure_dir(os.path.dirname(out_path))\n",
    "\n",
    "        written, err = process_one_csv(in_path, out_path)\n",
    "        if err:\n",
    "            print(f\"⚠️ Error: {in_path} -> {err}\")\n",
    "            error_files.append((in_path, err))\n",
    "            if os.path.exists(out_path) and os.path.getsize(out_path) == 0:\n",
    "                os.remove(out_path)\n",
    "        else:\n",
    "            if written == 0 and os.path.exists(out_path):\n",
    "                os.remove(out_path)\n",
    "            total_rows += written\n",
    "\n",
    "    print(\"\\n✅ finished\")\n",
    "    print(f\" number of pass row condition: {total_rows:,}\")\n",
    "    if error_files:\n",
    "        print(f\"⚠️ number of file that contain the error {len(error_files)} files (maximum display 10 files):\")\n",
    "        for p, e in error_files[:10]:\n",
    "            print(f\"   - {p} | {e}\")\n",
    "        if len(error_files) > 10:\n",
    "            print(\"   ...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พบไฟล์ .csv ทั้งหมด 276 ไฟล์\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSVs: 100%|██████████| 276/276 [01:42<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ เสร็จสิ้น\n",
      "➡️ แถวทั้งหมดที่ผ่านเงื่อนไข: 40,710,538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_ROOT  = \"/Users/kukkaii/Documents/DA PRoject/Clean_RoadData/Tambon/Filtered_engine1_light0\"\n",
    "OUTPUT_ROOT = \"/Users/kukkaii/Documents/DA PRoject/Clean_RoadData/Tambon/Weekend_3_10_11\"\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def process_one_csv(in_path, out_path):\n",
    "    \"\"\"อ่านไฟล์ CSV, กรองเสาร์-อาทิตย์ เดือน 3,10,11 แล้วบันทึกผล\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(in_path, parse_dates=[\"Date\"])\n",
    "        if df.empty:\n",
    "            return 0, None\n",
    "\n",
    " \n",
    "        df[\"month\"] = df[\"Date\"].dt.month\n",
    "        df[\"weekday\"] = df[\"Date\"].dt.dayofweek  # 0=Mon ... 5=Sat, 6=Sun\n",
    "\n",
    "        # filter for month 3,10,11 and sat-sun\n",
    "        mask = df[\"month\"].isin([3, 10, 11]) & df[\"weekday\"].isin([5, 6])\n",
    "        df_weekend = df.loc[mask, [\"lat\", \"lon\", \"Date\", \"speed_kmh\"]]\n",
    "\n",
    "        if not df_weekend.empty:\n",
    "            ensure_dir(os.path.dirname(out_path))\n",
    "            df_weekend.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "            return len(df_weekend), None\n",
    "        else:\n",
    "            return 0, None\n",
    "    except Exception as e:\n",
    "        return 0, str(e)\n",
    "\n",
    "def main():\n",
    "\n",
    "    csv_files = []\n",
    "    for root, _, files in os.walk(INPUT_ROOT):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(root, f))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"not found the .csv at that filder\")\n",
    "        return\n",
    "\n",
    "    print(f\"found .csv {len(csv_files)} files\")\n",
    "    total_rows = 0\n",
    "    error_files = []\n",
    "\n",
    "    for in_path in tqdm(csv_files, desc=\"Processing CSVs\"):\n",
    "\n",
    "        rel_path = os.path.relpath(in_path, INPUT_ROOT)\n",
    "        out_path = os.path.join(OUTPUT_ROOT, rel_path)\n",
    "\n",
    "        rows, err = process_one_csv(in_path, out_path)\n",
    "        total_rows += rows\n",
    "        if err:\n",
    "            error_files.append((in_path, err))\n",
    "\n",
    "    print(\"\\n✅ finished\")\n",
    "    print(f\"➡️ row that pass the condition: {total_rows:,}\")\n",
    "    if error_files:\n",
    "        print(f\" file have error {len(error_files)} files:\")\n",
    "        for p, e in error_files[:10]:\n",
    "            print(f\"   - {p} | {e}\")\n",
    "        if len(error_files) > 10:\n",
    "            print(\"   ...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AreaLocCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
